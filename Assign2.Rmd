---
title: "Assign2"
author: "Qiana Yang"
date: "10/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### a)

```{r}
# read file
gradAdmit <- read.csv(here::here("gradAdmit.csv"))

# examine file
summary(gradAdmit)
head(gradAdmit)

```

```{r}
# split the data into training, testing, and validation data sets

set.seed(12345)

# number of samples
n <- nrow(gradAdmit)

# hold out 20% for testing
sample <- sample.int(n = n, size = floor(.2 * n), replace = F)

train <- gradAdmit[-sample,]
test <- gradAdmit[sample,]
```

```{r}
# split training set into 5 folds 

library(caret)
set.seed(12345)

nfolds = 5
folds = createFolds(rownames(train), k = nfolds)

```

#### b)

```{r}

library(e1071)

# draft: basic svm function
# for a 5-fold cv training set defined in a), we apply the svm function and test it on the respective test set. 
# for each of the prediction results, we calculate its accuracy.
# define a lapply function that repeats the process for each training set/test set pairs.
# calculate mean accuracy.

cv <- function(x) {
  # perform svm
  svmfunc <- svm(formula = factor(admit)~., 
      data = train[-x,],
      scale = T
      )
  # predict on test set
  prediction <- predict(svmfunc, train[x,], type="response")
  # calculate accuracy
  accuracy <- 1 - (sum(abs(as.numeric(prediction) - 1 - train[x,1]))/nrow(train[x,]))
  # return accuracy rate
  return(accuracy)
}
# calculate mean accuracy
mean(as.numeric(lapply(folds, cv))) 

# the default function returns an accuracy rate of 72%
```
```{r}
# try different kernel functions, hyperparameters, and costs. Create custom grid.
# modify the cv function above to take in different hyperparameters for each kernel function. 

# create grid based on different combinations of all values below
degree <- c(3, 4, 5, 6, 7)
gamma <- c(0.001, 0.1, 0.2, 0.3)
coef0 <- c(0, 1, 3, 5, 7)
cost <- c(0.01, 0.1, 1, 10, 100)

grid_linear <- expand.grid("linear", NA, NA, NA, cost)
grid_poly <- expand.grid("polynomial", degree, gamma, coef0, cost)
grid_rad <- expand.grid("radial", NA, gamma, NA, cost)
grid_sig <- expand.grid("sigmoid", NA, gamma, coef0, cost)

grid <- rbind(grid_linear, grid_poly, grid_rad, grid_sig)
grid <- as.matrix(grid)
```

```{r}
# pass each row in grid to the svm function and calculate accuracy
# had to comment out this function when I knit the document because RStudio will break otherwise, but my results are accurate
accuracy_level <- function(grid_row) {
  
  # perform svm 
  cv <- function(x) {
    
    if (grid_row[1] == "linear") {
      svmfunc <- svm(formula = factor(admit)~., 
        data = train[-x,],
        scale = T,
        kernel = grid_row[1],
        cost = grid_row[5],
        cache = TRUE
      )
    }
      
    if (grid_row[1] == "polynomial") {
      svmfunc <- svm(formula = factor(admit)~., 
        data = train[-x,],
        scale = T,
        kernel = grid_row[1],
        degree = grid_row[2],
        gamma = grid_row[3],
        coef0 = grid_row[4],
        cost = grid_row[5],
        cache = TRUE
        )
    }
    
    if (grid_row[1] == "radial") {
      svmfunc <- svm(formula = factor(admit)~., 
        data = train[-x,],
        scale = T,
        kernel = grid_row[1],
        gamma = grid_row[3],
        cost = grid_row[5],
        cache = TRUE
        )
    }
    
    if (grid_row[1] == "sigmoid") {
      svmfunc <- svm(formula = factor(admit)~., 
        data = train[-x,],
        scale = T,
        kernel = grid_row[1],
        gamma = grid_row[3],
        coef0 = grid_row[4],
        cost = grid_row[5],
        cache = TRUE
        )
    }

    # predict on test set
    prediction <- predict(svmfunc, train[x,], type="response")
    # calculate accuracy
    accuracy <- 1 - (sum(abs(as.numeric(prediction) - 1 - train[x,1]))/nrow(train[x,]))
    # return accuracy rate
    return(accuracy)
  }
  
  # perform svm for each fold and return mean accuracy
  mean_accuracy <- mean(as.numeric(lapply(folds,cv)))
  #print(paste0("kernel: ", grid_row[1], 
              #", degree: ", grid_row[2], 
              #", gamma: ", grid_row[3], 
              #", coef0: ", grid_row[4], 
              #", cost: ", grid_row[5],
              #", accuracy: ", mean_accuracy
        #))
  return(mean_accuracy)
}

# perform the above function for all rows in grid
#accuracy_rate <- apply(X=grid, MARGIN=1, FUN=accuracy_level)

# create a summary table out of grid matrix
summary <- data.frame(grid)
names(summary)[1] <- "kernel"
names(summary)[2] <- "degree"
names(summary)[3] <- "gamma"
names(summary)[4] <- "coef0"
names(summary)[5] <- "cost"
#summary$accuracy <- accuracy_rate
#summary[summary$accuracy==max(summary$accuracy),]

# after many trials, the best accuracy rate is 73% from kernel = "radial", gamma = 0.2, and cost = 8
```

#### c)

```{r}
# retrain on the entire training set and test accuracy on test set
retrain <- svm(formula = factor(admit)~., 
      data = train,
      scale = T,
      kernel = "radial",
      gamma = 0.2,
      cost = 8
      )
# predict on test set
repredict <- predict(retrain, test, type="reponse")
# calculate accuracy
accuracy <- 1 - (sum(abs(as.numeric(repredict) - 1 - test[,1]))/nrow(test))
# return accuracy rate
accuracy

# accuracy rate on the test set is 66%

```

