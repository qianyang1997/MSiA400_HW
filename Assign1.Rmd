---
title: "MSiA 400 Lab Assignment 1"
subtitle: "Due Oct 13 at 5pm"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\underline{Instructions:} Please submit a report file that includes: a short answer, related code, printouts, etc. for each problem (where necessary). Push your answers to Github. All programming must be in R (or R Markdown).

## Problem 1

You will analyze data from a website with 8 pages (plus a 9th state, indicating that the user has left the website). Formulate a Markov chain for this website where each state $\{S_i\ |\ i=1,\cdots,9\}$ corresponds to a page. Each visitor starts at the home page (Page 1), then browses from page-to-page until he/she leaves the website. So, a sample path may be $S_1\to S_3\to S_5\to S_9$, corresponding to a visitor starting on the home page, moving to Page 3, then Page 5, then leaving the website.

Attached is the dataset `webtraffic.txt`, which records the paths of 1000 visitors (rows). The data has 81 columns labeled $t11,t12,\cdots,t19,t21,t22,\cdots,t99$, where $t_{ij}$ represents a transition from State $i$ to State $j$, for $i,j\in\{1,\cdots,9\}$. Each visitor has a 1 in column $t_{ij}$ if the visitor clicked from Page $i$ to Page $j$, and 0 elsewhere. For example, the aforementioned sample path would have 1's in columns $t_{13}$, $t_{35}$, and $t_{59}$ and 0's elsewhere.

### Problem 1a

Construct a 9 by 9 matrix `Traffic` that counts total traffic from State $i$ to State $j$, for $i,j\in\{1,\cdots,9\}$. Note that `Traffic` has 0's in row 9 and column 1. Set `Traffic[9,1]=1000`. (This is equivalent to making each user return to the home page after they leave the website.) Display `Traffic`. \underline{Hint:} `colSums()` adds all rows for each column.

```{r}

# read file
webtraffic <- read.table(here::here("webtraffic.txt"), header = TRUE)
head(webtraffic)

# create Traffic matrix
Traffic <- matrix(colSums(webtraffic), nrow = 9, ncol = 9, byrow = TRUE)

# set Traffic(9, 1) as 1000
Traffic[9, 1] <- 1000

# display Traffic
Traffic
```


### Problem 1b

Draw a directed graph where each node represents a state, and each arrow from State $i$ to State $j$ has positive (non-zero) traffic (i.e., `Traffic[i,j]>0`). This may be submitted as a TikZ graph (or using your graphing program of choice) or a picture of a hand-drawn graph (provided it is legible). Is the Markov chain irreducible? Is the Markov chain ergodic? Explain.

The Markov chain is irreducible, because you can get to every state (webpage) from any other state. More specifically, you can get to any state from state 1, and states 2-8 all point to 9. For any state i and j, if j = 1, then you can go from j to i. If j does not equal 1, then you can go from j to 9, 9 to 1, and 1 to i. 

The Markov chain is ergodic. Since it's irreducible, all states in the Markov chain share one communicating class. Therefore, these states must all be recurrent or all be transient. Since there is a finite number of states, the chain will return to each particular state an infinite number of times, so all states are recurrent. Also note that states 2-8 can directly pass to themselves, so these states are aperiodic. State 1 can return to itself via 1 - 3 - 9 - 1 (3 steps) or 1 - 2 - 4 - 9 - 1 (4 steps), with 1 as the greatest common divisor, so state 1 is aperiodic. Equivalently, state 9 can return to itself via 9 - 1 - 3 - 9 and 9 - 1 - 2 - 4 - 9, so it's also aperiodic. Thus, all states are aperiodic. Since all states are recurrent and periodic, the Markov chain is ergodic.


### Problem 1c

Construct and display the one-step transition probability matrix `P` (using the Maximum Likelihood estimate, i.e., $p_{ij}=\frac{\text{Traffic}[i,j]}{\sum\limits_{j=1}^9\text{Traffic}[i,j]}$).

```{r}
tmp <- rowSums(Traffic)
P <- Traffic / tmp
P
```


### Problem 1d

What is the probability of a visitor being on Page 5 after 5 clicks?

```{r}
a <- c(1, rep(0,8))
prob5 <- a %*% P %*% P %*% P %*% P %*% P
prob5[5]

```


### Problem 1e

Compute and display the steady-state probability vector `Pi`, solving the system of equations (as demonstrated in lab).

```{r}

Q <- t(P) - diag(9)
Q[9,] <- rep(1, 9)
rhs <- c(rep(0, 8), 1)
Pi <- solve(Q, rhs)
Pi
```


### Problem 1f

The following table represents the average time (in minutes) that a visitor spends on each page:

|Page|1|2|3|4|5|6|7|8|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|Min|0.1|2|3|5|5|3|3|2|

What is the average time a visitor spends on the website (until he/she first leaves)? \underline{Hint:} Modify the mean first passage time equations, with time spent at each state.

```{r}

B <- P[1:8, 1:8]
Q <- diag(8) - B
rhs = c(0.1, 2, 3, 5, 5, 3, 3, 2)
m <- solve(Q, rhs)
m[1]


```


## Problem 2

Use Monte Carlo integration to estimate the integral $\int\limits_0^\infty e^{-\lambda x} \sin x dx$ for $\lambda>0$. Use the exponential distribution $p(x)=\lambda e^{-\lambda x}$ for $x\ge0$, which has variance $\text{var}\left[p(x)\right]=\frac{1}{\lambda^2}$. Note, here $g(x)=\frac{\sin x}{\lambda}$. To generate random variables from the exponential distribution, you may first draw $X\sim\text{unif}(0,1)$, then let $Y=-\frac{\ln X}{\lambda}$. 

## Problem 2a

Determine the number of samples required to achieve an error tolerance of $10^{-3}$ with 99\% confidence.

```{r}



```


## Problem 2b

Compute the approximation (using the number of samples obtained in Problem 2a) and verify that it is within tolerance by comparing to the exact solution: $\int\limits_0^\infty e^{-\lambda x} \sin x dx=\frac{1}{1+\lambda^2}$. Numerically evaluate for each of $\lambda=1,2,4$.

```{r}
n <- 100000000

X <- runif(n,0,1)
Y <- -log(X) / 1
estimate1 <- (1/n) * sum(sin(Y)/1)
(estimate1 - 1/2)/(1/2)

Y <- -log(X) / 2
estimate2 <- (1/n) * sum(sin(Y)/2)
(estimate2 - 1/5)/(1/5)

Y <- -log(X) / 4
estimate3 <- (1/n) * sum(sin(Y)/4)
(estimate3 - 1/17)/(1/17)

# The error for lambda = 1 is -3.6e-05
# The error for lambda = 2 is 5.2e-06
# The error for lambda = 4 is 3.4e-05

```


## Problem 3

Obtain draws from the gamma distribution $p(x)=\frac{x^{k-1}}{\Gamma(k)\theta^k}\exp\left(-\frac{x}{\theta}\right)$ using MCMC. Use the exponential distribution $p(x)=\lambda e^{-\lambda x}$ as $q(\cdot|\cdot)$, with your previous iterate as $\lambda$.

## Problem 3a

Which MCMC algorithm (Metropolis, Metropolis-Hastings, or Gibbs) is better suited for this problem?

```{r}
# Answer: Hastings, because the exponential distribution is asymmetrical.
```

## Problem 3b

Using a burn-in period of 5000 samples and keeping every 100 samples, generate 100 samples from the gamma distribution with shape $k=2$ and scale $\theta=2$. Use the algorithm you chose in Problem 3a and write your own sampler (as opposed to using a function from a package).

```{r}
# set x_0 = 1
x <- c(1)

# set q(x|y)
q <- function(y, x) {return(y * exp(-y * x))}

# set f(x)
f <- function(x) {return(x * exp(-x / 2))}

# loop
for (t in 1:15000) {
  x_prime <- rexp(1, x[t])
  alpha <- f(x_prime) * q(x_prime, x[t]) / (f(x[t]) * q(x[t], x_prime))
  u <- runif(1)

  if (u <= alpha) {
    x[t + 1] <- x_prime
  } else {
    x[t + 1] <- x[t]
  }
}

# generate 100 samples by removing the first 5000 terms and keep every 100 term of x
x <- x[-c(1:5000)]
x <- x[seq(1, 9901, 100)]
x
```


## Problem 3c

Are the samples generated in Problem 3b sufficiently random? How can you tell?

```{r}

acf(x)

```


